{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d47a5d-15de-48a6-be56-8419fe122156",
   "metadata": {
    "tags": []
   },
   "source": [
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    ")\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, RobertaPreTrainedModel\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "import random\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from conf.dao_config import simcse_recipe_ingredients_dir,simcse_recipe_title_dir,MILVUS_HOST\n",
    "\n",
    "recipes = pd.read_csv(\"recipe/recipe.csv\")\n",
    "\n",
    "\n",
    "data = Dataset.from_pandas(recipes[[\"ingredients\"]])\n",
    "\n",
    "dataloader = DataLoader(data,batch_size=32)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(simcse_recipe_ingredients_dir)\n",
    "model = AutoModel.from_pretrained(simcse_recipe_ingredients_dir)\n",
    "model.eval()\n",
    "\n",
    "embedding = []\n",
    "with torch.no_grad():\n",
    "    for dataset in tqdm(dataloader):\n",
    "        data_feature = tokenizer(dataset['ingredients'],padding=\"max_length\",max_length=128,truncation=True,return_tensors=\"pt\")\n",
    "        data_embedding = model(**data_feature)\n",
    "        embedding.append(data_embedding.pooler_output)\n",
    "\n",
    "embedding = list(chain.from_iterable(embedding))\n",
    "embedding = [i.detach().numpy() for  i in embedding]\n",
    "\n",
    "connections.connect(\"default\",host=MILVUS_HOST, port=\"19530\")\n",
    "\n",
    "if utility.has_collection(\"COMP9900\"):\n",
    "    drop_collection(\"COMP9900\", timeout=None, using='default')\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"index\", dtype=DataType.INT64, is_primary=True),\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=768)\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, \"COMP9900\")\n",
    "hello_milvus = Collection(\"COMP9900\", schema)\n",
    "\n",
    "utility.list_collections()\n",
    "\n",
    "\n",
    "entity = [\n",
    "    [i+1 for i in range(len(embedding))],\n",
    "    embedding]\n",
    "\n",
    "insert_result = hello_milvus.insert(entity)\n",
    "\n",
    "index_params = {\n",
    "  \"metric_type\":\"IP\",\n",
    "  \"index_type\":\"IVF_FLAT\",\n",
    "  \"params\":{\"nlist\":1024}\n",
    "}\n",
    "\n",
    "collection.create_index(\n",
    "  field_name=\"embeddings\", \n",
    "  index_params=index_params\n",
    ")\n",
    "\n",
    "\n",
    "data = Dataset.from_pandas(recipes[[\"title\"]])\n",
    "\n",
    "dataloader = DataLoader(data,batch_size=32)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(simcse_recipe_title_dir)\n",
    "model = AutoModel.from_pretrained(simcse_recipe_title_dir)\n",
    "model.eval()\n",
    "\n",
    "embedding = []\n",
    "with torch.no_grad():\n",
    "    for dataset in tqdm(dataloader):\n",
    "        data_feature = tokenizer(dataset['title'],padding=\"max_length\",max_length=128,truncation=True,return_tensors=\"pt\")\n",
    "        data_embedding = model(**data_feature)\n",
    "        embedding.append(data_embedding.pooler_output)\n",
    "\n",
    "embedding = list(chain.from_iterable(embedding))\n",
    "embedding = [i.detach().numpy() for  i in embedding]\n",
    "\n",
    "connections.connect(\"default\",host=MILVUS_HOST, port=\"19530\")\n",
    "\n",
    "if utility.has_collection(\"recipe_title_search\"):\n",
    "    drop_collection(\"recipe_title_search\", timeout=None, using='default')\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"index\", dtype=DataType.INT64, is_primary=True),\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=768)\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, \"recipe_title_search\")\n",
    "hello_milvus = Collection(\"recipe_title_search\", schema)\n",
    "\n",
    "utility.list_collections()\n",
    "\n",
    "\n",
    "entity = [\n",
    "    [i+1 for i in range(len(embedding))],\n",
    "    embedding]\n",
    "\n",
    "insert_result = hello_milvus.insert(entity)\n",
    "\n",
    "index_params = {\n",
    "  \"metric_type\":\"IP\",\n",
    "  \"index_type\":\"IVF_FLAT\",\n",
    "  \"params\":{\"nlist\":1024}\n",
    "}\n",
    "\n",
    "collection.create_index(\n",
    "  field_name=\"embeddings\", \n",
    "  index_params=index_params\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import clip\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    ")\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, RobertaPreTrainedModel\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import normalize\n",
    "import random\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-B/32\")\n",
    "\n",
    "data = Dataset.from_pandas(recipes[[\"title\"]])\n",
    "\n",
    "dataloader = DataLoader(data,batch_size=64)\n",
    "\n",
    "text_model.eval\n",
    "embedding = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for dataset in tqdm(dataloader):\n",
    "        inputs = clip.tokenize(dataset['title'])\n",
    "        data_embedding = model.encode_text(inputs)\n",
    "        embedding.append(data_embedding)\n",
    "\n",
    "embedding = list(chain.from_iterable(embedding))\n",
    "\n",
    "embedding = [i.detach().numpy() for  i in embedding]\n",
    "\n",
    "connections.connect(\"default\",host=\"120.55.40.153\", port=\"19530\")\n",
    "\n",
    "if utility.has_collection(\"recipe_image_search\"):\n",
    "    utility.drop_collection(\"recipe_image_search\")\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"index\", dtype=DataType.INT64, is_primary=True),\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=embedding[0].shape[0])\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, \"recipe_image_search\")\n",
    "hello_milvus = Collection(\"recipe_image_search\", schema)\n",
    "\n",
    "index_params = {\n",
    "  \"metric_type\":\"IP\",\n",
    "  \"index_type\":\"IVF_FLAT\",\n",
    "  \"params\":{\"nlist\":1024}\n",
    "}\n",
    "\n",
    "hello_milvus.create_index(\n",
    "  field_name=\"embeddings\", \n",
    "  index_params=index_params\n",
    ")\n",
    "\n",
    "hello_milvus = Collection(\"recipe_image_search\", schema)\n",
    "\n",
    "entity = [\n",
    "    [i+1 for i in range(len(embedding))],\n",
    "    embedding]\n",
    "\n",
    "insert_result = hello_milvus.insert(entity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
